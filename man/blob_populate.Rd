% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions_core.R
\name{blob_populate}
\alias{blob_populate}
\title{Populate solutions by weighted sum scalarisation}
\usage{
blob_populate(
  data,
  k,
  r_range = c(0.5, 1),
  iter = 3L,
  run = 10L,
  space_distmat,
  sigma,
  converge_ari = NULL,
  crs = 4326,
  filter_intersects = T,
  filter_clustsize = T,
  max_na = 0.05,
  ...
)
}
\arguments{
\item{data}{a data matrix or data frame.}

\item{k}{an integer of the number of clusters.}

\item{r_range}{a numeric vector of length 2 indicating the lower and upper bounds of the relative spatial weight. They must be \eqn{[0,1]}.}

\item{iter}{an integer of the number of iterations. Default is 3L.}

\item{run}{an integer of the number of runs. Default is 10L.}

\item{space_distmat}{a numeric spatial distance matrix.}

\item{sigma}{a numeric value of sigma passed on to \code{\link[=rbf]{rbf()}}.}

\item{converge_ari}{a numeric value of Adjusted Rand Index (ARI) that sets convergence threshold between two searches. It must be \eqn{[0,1]}. Default is NULL.}

\item{crs}{a numeric value of the Coordinate Reference System passed on to \code{\link[sf:st_as_sf]{sf::st_as_sf()}} for geometry. Default is 4326.}

\item{filter_intersects}{a logical operator. Should an assignment with intersects in space be removed? Default is T.}

\item{filter_clustsize}{a logical operator. Should a cluster below the critical size be assigned NA? Default is T.}

\item{max_na}{a numeric value of the maximum proportion of NAs allowed. It must be \eqn{[0,1]}. Default is 0.05.}

\item{...}{the optional arguments include \code{random_start}.
\itemize{
\item \code{random_start}: a logical operator. Should random start or \code{\link[=start_blobs]{start_blobs()}} be used? Default is F.
}}
}
\value{
a list of the following objects.
\itemize{
\item \code{clust}: a numeric matrix of cluster assignments. Each row is a solution.
\item \code{summary}: a data frame of summary statistics.
\item \code{trace}: a data frame of summary statistics for tracing.
\item \code{n_filtered}: a data frame of numbers of filtered solutions.
}
}
\description{
This function populates solutions by weighted sum scalarisation of the bi-objective function in \code{\link[=blob_search]{blob_search()}} for a given k.
}
\details{
Gaussian kernel is applied to compute cluster centroids and non-spherical clusters in space.

Clusters are assigned in every iteration. It iterates until the set length or convergence.

When \code{converge_ari} is specified, convergence is defined and activated when ARI between the latest and the previous search is
above the specified threshold and at least three iterations are run.

The critical size of a cluster is defined as \eqn{\frac{N}{2k}} where \eqn{N} is the number of data point and \eqn{k} is the number of clusters.

Scalarisation is achieved by varying the relative spatial weight generated by Latin hypercube sampling using \code{\link[lhs:randomLHS]{lhs::randomLHS()}}.

To parallelise runs, \code{\link[future.apply:future_lapply]{future.apply::future_lapply()}} is implemented. See \link[future:future]{future::future} and \link[future.apply:future.apply]{future.apply::future.apply} for more information.
}
\seealso{
\code{\link[sf:st_as_sf]{sf::st_as_sf()}}, \code{\link[lhs:randomLHS]{lhs::randomLHS()}}, \code{\link[mclust:adjustedRandIndex]{mclust::adjustedRandIndex()}}, \link[future:future]{future::future}, \link[future.apply:future.apply]{future.apply::future.apply}
}
